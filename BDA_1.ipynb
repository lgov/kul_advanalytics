{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss, roc_auc_score, plot_roc_curve\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\",500)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"./assignment1/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-nirvana",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i)\n",
    "    try:\n",
    "        df[i].plot(kind=\"hist\")\n",
    "        plt.show()\n",
    "        print(df[i].describe())\n",
    "    except TypeError:\n",
    "        values = df[i].value_counts()\n",
    "        if len(values) < 10:\n",
    "            values.plot(kind=\"bar\")\n",
    "            plt.show()\n",
    "            print(df[i].describe())\n",
    "        else:\n",
    "            print('*******too many values to plot*******************')\n",
    "            print(df[i].describe())\n",
    "    print('*************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning functions\n",
    "def text_to_binary(col_name, bin_1, bin_0):\n",
    "    return df[col_name].replace({bin_0:0,bin_1:1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert binary text variables into binary: {\"Y\":1, \"N\":0}\n",
    "for i in [\"fraud\", \"claim_liable\", \"claim_police\", \"driver_injured\"]:\n",
    "    text_to_binary(i, \"Y\", \"N\")\n",
    "# {\"P\":1, \"N\":0}\n",
    "text_to_binary(\"claim_alcohol\", \"P\", \"N\")\n",
    "# {\"car\":1, \"van\":0}\n",
    "text_to_binary(\"claim_vehicle_type\", \"car\", \"van\")\n",
    "# {\"M\":1, \"F\":0}\n",
    "text_to_binary(\"policy_holder_form\", \"M\", \"F\")\n",
    "# {\"B\":1, \"N\":0}\n",
    "text_to_binary(\"policy_holder_country\", \"B\", \"N\")\n",
    "# make claim_lang binary (currently 1:Dutch, 2:Fr) -> 0: Dutch and 1: French\n",
    "df[\"claim_language\"] = df[\"claim_language\"] - 1 \n",
    "\n",
    "# replace \",\" with \".\" and convert to numeric\n",
    "df[\"claim_amount\"] = pd.to_numeric(df[\"claim_amount\"].str.replace(\",\", \".\"))\n",
    "\n",
    "# get dummies for cat vars\n",
    "df = pd.get_dummies(df, dummy_na=True, columns=[\"claim_cause\"])\n",
    "\n",
    "# format date\n",
    "YYYYMMDD_date_columns = [\"claim_date_registered\",\n",
    "                         \"claim_date_occured\"]\n",
    "for i in YYYYMMDD_date_columns:\n",
    "    df[i] = pd.to_datetime(df[i], format=\"%Y%m%d\")\n",
    "\n",
    "# remove extreme value\n",
    "df[\"claim_vehicle_date_inuse\"].replace(to_replace=270505.0, value= np.nan, inplace=True)\n",
    "\n",
    "YYYYMM_columns = [\"claim_vehicle_date_inuse\", \n",
    "                  \"policy_date_start\",\n",
    "                  \"policy_date_next_expiry\",\n",
    "                  \"policy_date_last_renewed\"]\n",
    "for i in YYYYMM_columns:\n",
    "    df[i] = pd.to_datetime(df[i], format=\"%Y%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped for now but can be added for futher improvement\n",
    "drop_temp = [\n",
    "    \"claim_postal_code\", # rural area\n",
    "    \"claim_vehicle_brand\", # premium or not\n",
    "    \"claim_time_occured\", # could derive morning, noon, afternoon, evening, night or day/night\n",
    "    \"claim_vehicle_cyl\", \n",
    "    \"claim_vehicle_load\", \n",
    "    \"claim_vehicle_fuel_type\", \n",
    "    \"claim_vehicle_power\", # buckets?\n",
    "    \"policy_holder_postal_code\", # rural area\n",
    "    \"policy_holder_year_birth\", # age\n",
    "    \"third_party_1_postal_code\",\n",
    "    \"third_party_1_injured\",\n",
    "    \"third_party_1_vehicle_type\",\n",
    "    \"third_party_1_form\",\n",
    "    \"third_party_1_year_birth\",\n",
    "    \"third_party_1_country\",\n",
    "    \"repair_postal_code\",\n",
    "    \"repair_form\",\n",
    "    \"repair_year_birth\",\n",
    "    \"repair_country\",\n",
    "    \"repair_sla\",\n",
    "    \"policy_coverage_type\",\n",
    "    \"driver_postal_code\", \n",
    "    \"driver_form\", \n",
    "    \"driver_year_birth\", \n",
    "    \"driver_country\", \n",
    "    \"driver_injured\",\n",
    "    \"claim_amount\"\n",
    "]\n",
    "\n",
    "# date variables are also dropped for first analysis\n",
    "drop_dates = [\"claim_date_registered\",\n",
    "              \"claim_date_occured\", # could be interesting to calculate time between occured and registered\n",
    "              \"claim_vehicle_date_inuse\", \n",
    "              \"policy_date_start\",\n",
    "              \"policy_date_next_expiry\",\n",
    "              \"policy_date_last_renewed\"\n",
    "             ]\n",
    "\n",
    "# all ID variables are dropped\n",
    "drop_forever = [\"claim_vehicle_id\",\n",
    "                \"claim_id\",\n",
    "                \"policy_holder_id\", \n",
    "                \"policy_holder_expert_id\",\n",
    "                \"driver_id\", \n",
    "                \"driver_expert_id\", \n",
    "                \"driver_vehicle_id\",\n",
    "                \"claim_vehicle_id\",\n",
    "                \"third_party_1_id\",\n",
    "                \"third_party_1_vehicle_id\",\n",
    "                \"third_party_1_expert_id\",\n",
    "                \"repair_id\"\n",
    "               ]\n",
    "df.drop(columns=drop_temp + drop_dates + drop_forever, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude columns with over 50k missing values (i.e. over 90%)\n",
    "missing_over_90prct = df.isna().sum().index[np.where(df.isna().sum() > 50000)]\n",
    "df.drop(columns=missing_over_90prct, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute remaining missing values with mode or mean\n",
    "# here it could potentially make sense to include a third category (i.e. missing), although this would be a small cat\n",
    "\n",
    "# mode\n",
    "df[\"claim_language\"].fillna(df[\"claim_language\"].mode()[0], inplace=True)\n",
    "df[\"claim_vehicle_type\"].fillna(df[\"claim_vehicle_type\"].mode()[0], inplace=True)\n",
    "\n",
    "# mean\n",
    "df[\"policy_premium_100\"].fillna(df[\"policy_premium_100\"].mean(), inplace=True)\n",
    "df[\"policy_coverage_1000\"].fillna(df[\"policy_coverage_1000\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure all missing values have been addressed\n",
    "assert df.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-conspiracy",
   "metadata": {},
   "source": [
    "# Base model - off the shelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,1:], df[\"fraud\"], test_size=.2, random_state=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "plot_roc_curve(clf, X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
