{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da83c47e",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "* To install PyTorch. Follow the steps in [this](https://pytorch.org/get-started/locally/) link\n",
    "* see [here](https://pypi.org/project/split-folders/) for more information on the splitfolders package used in 'helper'\n",
    "* general example to follow: see [here](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html), [here](https://towardsdatascience.com/a-practical-example-in-transfer-learning-with-pytorch-846bb835f2db), or [here](https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a76078",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fde30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "from helper import InstagramDataset, data_labeler, ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22f7d2",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbde753",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that splitting the data into split, val, test and reorganizing folders accordingly is a slow process\n",
    "# this operation can take up to 15-30min. Check the function to get an idea what is going on in the background\n",
    "data_labeler(target_dir='recipes_labeled', source_dir='recipes/recipes/', bins=bins,\n",
    "             target_name='likes', metadata_path='recipes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bdfb88",
   "metadata": {},
   "source": [
    "# Reading Instadata following PyTorch convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63113752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we load the Instagram dataset through a custom class, this class reads the data, applies transformations,\n",
    "# and creates batches for train, test, and val data as iterators (i.e. dataloaders)\n",
    "# see docstring for further information\n",
    "insta_data = InstagramDataset('recipes_labeled_splitted')\n",
    "dataloaders = insta_data.dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check random image, works especially well if you're hungry... :)\n",
    "insta_data.imshow(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4cbc21",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fb9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "resn = ResNet(dataloaders, insta_data.dataset_sizes, pretrained=True) #initialize the ResNet defined in helper\n",
    "model = resn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06250cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() #the original resnet 50 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ee6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# extract number of nodes in last fc layer and add own fc layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, bins) # from 2048 to 10 (i.e. our target)\n",
    "\n",
    "model = model.to(resn.device)\n",
    "\n",
    "# set objective criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only params in last fc layer are optimized\n",
    "optimizer_ft = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe how the last layer has been replaced by our own layer\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebdd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resn.train_model(criterion, optimizer_ft, exp_lr_scheduler, num_epochs=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
