{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.46.133.247:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.46.133.247:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd5c40107f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import ltrim\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all letters to lowercase\n",
    "#df = df.withColumn(\"tweet_text\",f.lower(f.col(\"tweet_text\")))\n",
    "\n",
    "#removing punctuations, numbers, http and spaces\n",
    "#df =df.withColumn(\"tweet_text\",f.regexp_replace(f.col(\"tweet_text\"),'([^ a-zA-Z\\'])',''))\n",
    "#df = df.withColumn(\"tweet_text\",f.regexp_replace(f.col(\"tweet_text\"),'http.*?\\\\b',' '))\n",
    "#df = df.withColumn(\"tweet_text\",f.ltrim(f.regexp_replace(f.col(\"tweet_text\"),'[\\r\\n\\t\\f\\v ]+', ' ')))\n",
    "\n",
    "\n",
    "#from pyspark.ml.feature import Tokenizer\n",
    "#from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "#Splitting words\n",
    "\n",
    "#tokenizer = Tokenizer(inputCol=\"tweet_text\", outputCol=\"words\")\n",
    "#dataset = tokenizer.transform(df)\n",
    "\n",
    "#pandas_df = dataset.select(\"*\").toPandas()\n",
    "#pandas_df['lemmatized'] = pandas_df['words'].apply(lambda lst:[lemmatizer.lemmatize(word) for word in lst])\n",
    "#pandas_df['lemmatized']\n",
    "#dataset2 = spark.createDataFrame(pandas_df)\n",
    "\n",
    "#Vectorizing\n",
    "#from pyspark.ml.feature import CountVectorizer, StringIndexer\n",
    "\n",
    "\n",
    "#cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "#label_stringIdx = StringIndexer(inputCol = \"label\", outputCol = \"labelIndex\")\n",
    "\n",
    "#pipeline = Pipeline(stages=[cv, label_stringIdx])\n",
    "\n",
    "#pipelineFit = pipeline.fit(dataset2)\n",
    "#dataset2 = pipelineFit.transform(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = True\n",
    "globals()['my_model'] = PipelineModel.load(\"lr_model\")\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df.show()\n",
    "    \n",
    "    # Utilize our predict function\n",
    "   #df_withpreds = df.withColumn(\"pred\", predict_udf(\n",
    "       #struct([df[x] for x in df.columns])\n",
    "    #))\n",
    "    #df_withpreds.show()\n",
    "        \n",
    "    # Normally, you wouldn't use a UDF (User Defined Function) Python function to predict as we did here (you can)\n",
    "    # but an MLlib model you've built and saved with Spark\n",
    "    # In this case, you need to prevent loading your model in every call to \"process\" as follows:\n",
    "    \n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = '***' # Replace '***' with:    [...].load('my_logistic_regression')\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    prediction = globals()['my_model'].transform(df)\n",
    "    selected = prediction.select(\"labelIndex\", \"prediction\")\n",
    "    for row in selected.collect():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2021-05-28 11:51:30 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#china|1398212783217414149|#███████ have bee...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelIndex=2.0, prediction=2.0)\n",
      "========= 2021-05-28 11:51:40 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#china|1398212667110744065|Dujiangyan Zhongs...|\n",
      "|#china|1398212624253345792|Will add: There a...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelIndex=2.0, prediction=1.0)\n",
      "Row(labelIndex=2.0, prediction=2.0)\n",
      "========= 2021-05-28 11:52:00 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#china|1398212514781958148|Understanding #██...|\n",
      "|#china|1398212509954359297|The medal commemo...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelIndex=2.0, prediction=2.0)\n",
      "Row(labelIndex=2.0, prediction=2.0)\n",
      "========= 2021-05-28 11:52:10 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398212925106442243|For people that a...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelIndex=0.0, prediction=2.0)\n",
      "========= 2021-05-28 11:52:30 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398212904416075777|@Dr2NisreenAlwan ...|\n",
      "|#covid|1398212872082280452|#███████ reschedu...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelIndex=0.0, prediction=0.0)\n",
      "Row(labelIndex=0.0, prediction=2.0)\n",
      "========= 2021-05-28 11:52:40 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398212823759482881|@MaaroPancho @s_k...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelIndex=0.0, prediction=2.0)\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "========= 2021-05-28 11:52:50 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398212978000809985|Verified...\n",
      "Oxyge...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelIndex=0.0, prediction=0.0)\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
