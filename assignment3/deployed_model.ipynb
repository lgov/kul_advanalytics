{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f825ff0e7f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import ltrim\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, StringIndexer, IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasOutputCols, Param, Params\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.functions import lit # for the dummy _transform\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import ltrim\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "\n",
    "class RegexReplacerWritable(\n",
    "    Transformer, DefaultParamsReadable, DefaultParamsWritable,\n",
    "):\n",
    "    #value = Param(\n",
    "    #   Params._dummy(),\n",
    "    #   \"value\",\n",
    "    #   \"value to fill\",\n",
    "    #)\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self):\n",
    "        super(RegexReplacerWritable, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self._set(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self):\n",
    "        \"\"\"\n",
    "        setParams(self, outputCols=None, value=0.0)\n",
    "        Sets params for this RegexReplacerWritable.\n",
    "        \"\"\"\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        #Converting all letters to lowercase\n",
    "        df = df.withColumn(\"tweet_text\",f.lower(f.col(\"tweet_text\")))\n",
    "        #removing punctuations, numbers, http and spaces\n",
    "        df = df.withColumn(\"tweet_text\",f.regexp_replace(f.col(\"tweet_text\"),'([^ a-zA-Z\\'])',''))\n",
    "        df = df.withColumn(\"tweet_text\",f.regexp_replace(f.col(\"tweet_text\"),'http.*?\\\\b',' '))\n",
    "        df = df.withColumn(\"tweet_text\",f.ltrim(f.regexp_replace(f.col(\"tweet_text\"),'[\\r\\n\\t\\f\\v ]+', ' ')))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasOutputCols, Param, Params\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.functions import lit # for the dummy _transform\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import ltrim\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class UDShortWordsRemover(\n",
    "    Transformer, DefaultParamsReadable, DefaultParamsWritable,\n",
    "):\n",
    "    @keyword_only\n",
    "    def __init__(self):\n",
    "        super(UDShortWordsRemover, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self._set(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self):\n",
    "        \"\"\"\n",
    "        setParams(self, outputCols=None, value=0.0)\n",
    "        Sets params for this RegexReplacerWritable.\n",
    "        \"\"\"\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \n",
    "        df = df.withColumn(\"filtered2\", f.expr(\"filter(filtered, x -> not(length(x) < 3))\")).where(f.size(f.col(\"filtered2\")) > 0).drop(\"filtered\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasOutputCols, Param, Params\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.functions import lit # for the dummy _transform\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import ltrim\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "class UDLemmatization(\n",
    "    Transformer, DefaultParamsReadable, DefaultParamsWritable,\n",
    "):\n",
    "    @keyword_only\n",
    "    def __init__(self):\n",
    "        super(UDLemmatization, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self._set(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self):\n",
    "        \"\"\"\n",
    "        setParams(self, outputCols=None, value=0.0)\n",
    "        Sets params for this RegexReplacerWritable.\n",
    "        \"\"\"\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer() \n",
    "        pandas_df = df.select(\"*\").toPandas()\n",
    "        pandas_df['lemmatized'] = pandas_df['words'].apply(\n",
    "                    lambda lst:[lemmatizer.lemmatize(word) for word in lst])\n",
    "        pandas_df['lemmatized']\n",
    "        df = spark.createDataFrame(pandas_df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = True\n",
    "globals()['my_model'] = PipelineModel.load(\"lr_model\")\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df.show()\n",
    "    \n",
    "    # Utilize our predict function\n",
    "    #df_withpreds = df.withColumn(\"pred\", predict_udf(\n",
    "     #  struct([df[x] for x in df.columns])\n",
    "    #))\n",
    "    #df_withpreds.show()\n",
    "    \n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = '***' # Replace '***' with:    [...].load('my_logistic_regression')\n",
    "        globals()['models_loaded'] = True\n",
    "    \n",
    "    prediction = globals()['my_model'].transform(df)\n",
    "    \n",
    "    ind_str = IndexToString(inputCol='prediction',outputCol='labelPredicted',labels=globals()['my_model'].stages[7].labels)\n",
    "    prediction_text = ind_str.transform(prediction)\n",
    "    selected = prediction_text.select(\"labelOriginal\", \"labelPredicted\")\n",
    "    for row in selected.collect():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2021-05-28 21:44:20 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362037969899522|#███████ Lifts #█...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:44:30 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398361991861862402|#███████ #███████...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#vaccine')\n",
      "========= 2021-05-28 21:44:40 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398361966096355335|New World Order E...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#china')\n",
      "========= 2021-05-28 21:44:50 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398361961222582273|WATCH BATRA'S BUR...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:45:00 =========\n",
      "+----------+-------------------+--------------------+\n",
      "|     label|           tweet_id|          tweet_text|\n",
      "+----------+-------------------+--------------------+\n",
      "|    #covid|1398361946546573312|People who think ...|\n",
      "|#inflation|1398362268476350464|ONE THIRD of all ...|\n",
      "+----------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#vaccine')\n",
      "Row(labelOriginal='#inflation', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:45:10 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362452488863748|We offer *FREE* N...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:45:30 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362333789949956|Answering #██████...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:45:40 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362297081335810|The Indian varian...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:45:50 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362594210103296|The FDA has not g...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#vaccine')\n",
      "========= 2021-05-28 21:46:00 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362567655845890|@KTRTRS sir,\n",
      "\n",
      "Ple...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:46:10 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362562698354695|Do your part, and...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:46:20 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362560454447109|Said Boris to Han...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:46:30 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#covid|1398362529177518087|Shillong, May 29:...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#covid', labelPredicted='#covid')\n",
      "========= 2021-05-28 21:46:40 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#biden|1398362814738321408|When is the MSM g...|\n",
      "|#china|1398363252804001796|#███████: We are ...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#biden', labelPredicted='#covid')\n",
      "Row(labelOriginal='#china', labelPredicted='#china')\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "========= 2021-05-28 21:46:50 =========\n",
      "+------+-------------------+--------------------+\n",
      "| label|           tweet_id|          tweet_text|\n",
      "+------+-------------------+--------------------+\n",
      "|#china|1398363091545563148|General Mark Mill...|\n",
      "+------+-------------------+--------------------+\n",
      "\n",
      "Row(labelOriginal='#china', labelPredicted='#china')\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
